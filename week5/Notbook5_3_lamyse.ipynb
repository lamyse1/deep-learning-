{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lamyse1/deep-learning-/blob/main/week5/Notbook5_3_lamyse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWv1PFkVZqRp"
      },
      "source": [
        "\n",
        "# AAI612: Deep Learning & its Applications\n",
        "\n",
        "*Notebook 5.3: KerasTuner*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxgVEhBDZqRr"
      },
      "source": [
        "Ensure that KerasTuner is installed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "i8CgT99bZqRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f61b5ed-1d86-4616-c8ea-e089711a07f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/129.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys4kf79pZqRs"
      },
      "source": [
        "Import KerasTuner and TensorFlow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "q7YhmSBUZqRs"
      },
      "outputs": [],
      "source": [
        "import keras_tuner\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "YYbwaukVZqRs"
      },
      "source": [
        "`KerasTuner` lets you replace hard-coded hyperparameter values, such as units=32, with a range of possible choices, such as `Int(name=\"units\", min_value=16, max_value=64, step=16)`. This set of choices in a given model is called the search space of the hyperparameter tuning process.  To specify a search space, define a model-building function (see the next listing).  It takes an hp argument, from which you can sample hyperparameter ranges, and it returns a compiled Keras model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Y3KbBa_dZqRt"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(units, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "    optimizer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJsuBoZUZqRt"
      },
      "source": [
        "**A KerasTuner `HyperModel`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eguLjmiMZqRt"
      },
      "source": [
        "We can also adopt a more modular and configurable approach to model-building by subclassing the HyperModel class and define a build method, as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6Vp3s9t1ZqRt"
      },
      "outputs": [],
      "source": [
        "import keras_tuner as kt\n",
        "\n",
        "class SimpleMLP(kt.HyperModel):\n",
        "    def __init__(self, num_classes):\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def build(self, hp):\n",
        "        units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)\n",
        "        model = keras.Sequential([\n",
        "            layers.Dense(units, activation=\"relu\"),\n",
        "            layers.Dense(self.num_classes, activation=\"softmax\")\n",
        "        ])\n",
        "        optimizer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])\n",
        "        model.compile(\n",
        "            optimizer=optimizer,\n",
        "            loss=\"sparse_categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"])\n",
        "        return model\n",
        "\n",
        "hypermodel = SimpleMLP(num_classes=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMbTzyLiZqRu"
      },
      "source": [
        "The next step is to define a “tuner.” Schematically, you can think of a tuner as a for loop that will repeatedly\n",
        "- Pick a set of hyperparameter values\n",
        "- Call the model-building function with these values to create a model\n",
        "- Train the model and record its metrics\n",
        "\n",
        "KerasTuner has several built-in tuners available—RandomSearch, BayesianOptimization, and Hyperband. Let’s try BayesianOptimization, a tuner that attempts to make smart predictions for which new hyperparameter values are likely to perform best given the outcomes of previous choices:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DV-_7BGDZqR0"
      },
      "outputs": [],
      "source": [
        "tuner = kt.BayesianOptimization(\n",
        "    build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=50,\n",
        "    executions_per_trial=2,\n",
        "    directory=\"mnist_kt_test\",\n",
        "    overwrite=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E8udJV6ZqR0"
      },
      "source": [
        "Display an overview of the search space via `search_space_summary()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9dIE854NZqR1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd73f297-323c-44bc-d596-f58ab2dbee48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 2\n",
            "units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 16, 'sampling': 'linear'}\n",
            "optimizer (Choice)\n",
            "{'default': 'rmsprop', 'conditions': [], 'values': ['rmsprop', 'adam'], 'ordered': False}\n"
          ]
        }
      ],
      "source": [
        "tuner.search_space_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GiOAY5ZcZqR1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fbaa3b6-1161-4b84-f01a-4618bcc1099a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 50 Complete [00h 01m 31s]\n",
            "val_accuracy: 0.9752500057220459\n",
            "\n",
            "Best val_accuracy So Far: 0.9759500026702881\n",
            "Total elapsed time: 01h 20m 38s\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape((-1, 28 * 28)).astype(\"float32\") / 255\n",
        "x_test = x_test.reshape((-1, 28 * 28)).astype(\"float32\") / 255\n",
        "x_train_full = x_train[:]\n",
        "y_train_full = y_train[:]\n",
        "num_val_samples = 10000\n",
        "x_train, x_val = x_train[:-num_val_samples], x_train[-num_val_samples:]\n",
        "y_train, y_val = y_train[:-num_val_samples], y_train[-num_val_samples:]\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
        "]\n",
        "tuner.search(\n",
        "    x_train, y_train,\n",
        "    batch_size=128,\n",
        "    epochs=60,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=callbacks,\n",
        "    verbose=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7txcYu4ZqR2"
      },
      "source": [
        "## Querying the best hyperparameter configurations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx7L6YrGZqR2"
      },
      "source": [
        "Once the search is complete, you can query the best hyperparameter configurations, which you can use to create high-performing models that you can then retrain:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Ax1FY-zXZqR2"
      },
      "outputs": [],
      "source": [
        "top_n = 4\n",
        "best_hps = tuner.get_best_hyperparameters(top_n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR6aIKIJZqR3"
      },
      "source": [
        "Before we can train on the full training data, though, there’s one last parameter we need to settle: the optimal number of epochs to train for. Typically, you’ll want to train the new models for longer than you did during the search: using an aggressive patience value in the EarlyStopping callback saves time during the search, but it may lead to under-fit models. Just use the validation set to find the best epoch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6A9fNSfRZqR3"
      },
      "outputs": [],
      "source": [
        "def get_best_epoch(hp):\n",
        "    model = build_model(hp)\n",
        "    callbacks=[\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            monitor=\"val_loss\", mode=\"min\", patience=10)\n",
        "    ]\n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        validation_data=(x_val, y_val),\n",
        "        epochs=100,\n",
        "        batch_size=128,\n",
        "        callbacks=callbacks)\n",
        "    val_loss_per_epoch = history.history[\"val_loss\"]\n",
        "    best_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
        "    print(f\"Best epoch: {best_epoch}\")\n",
        "    return best_epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi-gPhz3ZqR3"
      },
      "source": [
        "Finally, train on the full dataset for just a bit longer than this epoch count, since\n",
        "you’re training on more data; 20% more in this case:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OLaN6hVlZqR4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b84f3e61-e9eb-4969-8a0c-c05483aead08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7750 - loss: 0.8090 - val_accuracy: 0.9333 - val_loss: 0.2403\n",
            "Epoch 2/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9319 - loss: 0.2422 - val_accuracy: 0.9486 - val_loss: 0.1858\n",
            "Epoch 3/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9496 - loss: 0.1790 - val_accuracy: 0.9584 - val_loss: 0.1524\n",
            "Epoch 4/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9610 - loss: 0.1358 - val_accuracy: 0.9661 - val_loss: 0.1296\n",
            "Epoch 5/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9683 - loss: 0.1153 - val_accuracy: 0.9661 - val_loss: 0.1178\n",
            "Epoch 6/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9720 - loss: 0.0972 - val_accuracy: 0.9683 - val_loss: 0.1093\n",
            "Epoch 7/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9759 - loss: 0.0872 - val_accuracy: 0.9699 - val_loss: 0.1040\n",
            "Epoch 8/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9786 - loss: 0.0760 - val_accuracy: 0.9710 - val_loss: 0.0999\n",
            "Epoch 9/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9817 - loss: 0.0643 - val_accuracy: 0.9720 - val_loss: 0.0959\n",
            "Epoch 10/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9845 - loss: 0.0566 - val_accuracy: 0.9715 - val_loss: 0.0957\n",
            "Epoch 11/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9864 - loss: 0.0503 - val_accuracy: 0.9730 - val_loss: 0.0918\n",
            "Epoch 12/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.0464 - val_accuracy: 0.9724 - val_loss: 0.0948\n",
            "Epoch 13/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9887 - loss: 0.0427 - val_accuracy: 0.9734 - val_loss: 0.0884\n",
            "Epoch 14/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0374 - val_accuracy: 0.9750 - val_loss: 0.0855\n",
            "Epoch 15/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0319 - val_accuracy: 0.9743 - val_loss: 0.0857\n",
            "Epoch 16/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9932 - loss: 0.0289 - val_accuracy: 0.9741 - val_loss: 0.0893\n",
            "Epoch 17/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0272 - val_accuracy: 0.9743 - val_loss: 0.0905\n",
            "Epoch 18/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9941 - loss: 0.0239 - val_accuracy: 0.9757 - val_loss: 0.0903\n",
            "Epoch 19/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9953 - loss: 0.0214 - val_accuracy: 0.9735 - val_loss: 0.0961\n",
            "Epoch 20/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0203 - val_accuracy: 0.9738 - val_loss: 0.0916\n",
            "Epoch 21/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0169 - val_accuracy: 0.9751 - val_loss: 0.0917\n",
            "Epoch 22/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0158 - val_accuracy: 0.9742 - val_loss: 0.0968\n",
            "Epoch 23/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0140 - val_accuracy: 0.9746 - val_loss: 0.0955\n",
            "Epoch 24/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9977 - loss: 0.0129 - val_accuracy: 0.9763 - val_loss: 0.0957\n",
            "Best epoch: 14\n",
            "Epoch 1/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7991 - loss: 0.7313\n",
            "Epoch 2/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9362 - loss: 0.2284\n",
            "Epoch 3/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9539 - loss: 0.1635\n",
            "Epoch 4/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.1329\n",
            "Epoch 5/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9682 - loss: 0.1152\n",
            "Epoch 6/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9728 - loss: 0.0948\n",
            "Epoch 7/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9765 - loss: 0.0813\n",
            "Epoch 8/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9784 - loss: 0.0753\n",
            "Epoch 9/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9827 - loss: 0.0624\n",
            "Epoch 10/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9839 - loss: 0.0576\n",
            "Epoch 11/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9845 - loss: 0.0543\n",
            "Epoch 12/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.0470\n",
            "Epoch 13/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9890 - loss: 0.0413\n",
            "Epoch 14/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.0375\n",
            "Epoch 15/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9903 - loss: 0.0336\n",
            "Epoch 16/16\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0312\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9712 - loss: 0.0994\n",
            "Epoch 1/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7868 - loss: 0.7787 - val_accuracy: 0.9359 - val_loss: 0.2298\n",
            "Epoch 2/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9340 - loss: 0.2286 - val_accuracy: 0.9520 - val_loss: 0.1768\n",
            "Epoch 3/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9513 - loss: 0.1756 - val_accuracy: 0.9581 - val_loss: 0.1472\n",
            "Epoch 4/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9586 - loss: 0.1445 - val_accuracy: 0.9608 - val_loss: 0.1380\n",
            "Epoch 5/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9650 - loss: 0.1228 - val_accuracy: 0.9632 - val_loss: 0.1228\n",
            "Epoch 6/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9705 - loss: 0.1040 - val_accuracy: 0.9657 - val_loss: 0.1169\n",
            "Epoch 7/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9743 - loss: 0.0915 - val_accuracy: 0.9680 - val_loss: 0.1054\n",
            "Epoch 8/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9755 - loss: 0.0840 - val_accuracy: 0.9681 - val_loss: 0.1071\n",
            "Epoch 9/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9800 - loss: 0.0718 - val_accuracy: 0.9684 - val_loss: 0.1065\n",
            "Epoch 10/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9820 - loss: 0.0666 - val_accuracy: 0.9689 - val_loss: 0.1060\n",
            "Epoch 11/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9829 - loss: 0.0592 - val_accuracy: 0.9713 - val_loss: 0.0965\n",
            "Epoch 12/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9856 - loss: 0.0519 - val_accuracy: 0.9716 - val_loss: 0.0947\n",
            "Epoch 13/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: 0.0474 - val_accuracy: 0.9721 - val_loss: 0.0976\n",
            "Epoch 14/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.0433 - val_accuracy: 0.9698 - val_loss: 0.0981\n",
            "Epoch 15/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9895 - loss: 0.0396 - val_accuracy: 0.9714 - val_loss: 0.0958\n",
            "Epoch 16/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.0356 - val_accuracy: 0.9720 - val_loss: 0.0943\n",
            "Epoch 17/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9916 - loss: 0.0330 - val_accuracy: 0.9712 - val_loss: 0.0975\n",
            "Epoch 18/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.0279 - val_accuracy: 0.9720 - val_loss: 0.0957\n",
            "Epoch 19/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9933 - loss: 0.0276 - val_accuracy: 0.9713 - val_loss: 0.0986\n",
            "Epoch 20/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9944 - loss: 0.0243 - val_accuracy: 0.9732 - val_loss: 0.0988\n",
            "Epoch 21/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0212 - val_accuracy: 0.9749 - val_loss: 0.0967\n",
            "Epoch 22/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9956 - loss: 0.0191 - val_accuracy: 0.9712 - val_loss: 0.1054\n",
            "Epoch 23/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0184 - val_accuracy: 0.9739 - val_loss: 0.0986\n",
            "Epoch 24/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0169 - val_accuracy: 0.9735 - val_loss: 0.1018\n",
            "Epoch 25/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.0147 - val_accuracy: 0.9732 - val_loss: 0.1006\n",
            "Epoch 26/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0130 - val_accuracy: 0.9736 - val_loss: 0.1041\n",
            "Best epoch: 16\n",
            "Epoch 1/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7952 - loss: 0.7362\n",
            "Epoch 2/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9358 - loss: 0.2269\n",
            "Epoch 3/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9508 - loss: 0.1718\n",
            "Epoch 4/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9612 - loss: 0.1357\n",
            "Epoch 5/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9676 - loss: 0.1141\n",
            "Epoch 6/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9728 - loss: 0.0954\n",
            "Epoch 7/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9774 - loss: 0.0809\n",
            "Epoch 8/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9780 - loss: 0.0743\n",
            "Epoch 9/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9805 - loss: 0.0656\n",
            "Epoch 10/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9834 - loss: 0.0586\n",
            "Epoch 11/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9850 - loss: 0.0515\n",
            "Epoch 12/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0461\n",
            "Epoch 13/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9886 - loss: 0.0402\n",
            "Epoch 14/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9900 - loss: 0.0360\n",
            "Epoch 15/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9906 - loss: 0.0335\n",
            "Epoch 16/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9921 - loss: 0.0304\n",
            "Epoch 17/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9928 - loss: 0.0271\n",
            "Epoch 18/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9944 - loss: 0.0243\n",
            "Epoch 19/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0230\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9707 - loss: 0.0999\n",
            "Epoch 1/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7914 - loss: 0.7563 - val_accuracy: 0.9339 - val_loss: 0.2384\n",
            "Epoch 2/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9351 - loss: 0.2356 - val_accuracy: 0.9478 - val_loss: 0.1907\n",
            "Epoch 3/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9481 - loss: 0.1834 - val_accuracy: 0.9568 - val_loss: 0.1520\n",
            "Epoch 4/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9582 - loss: 0.1482 - val_accuracy: 0.9610 - val_loss: 0.1370\n",
            "Epoch 5/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9642 - loss: 0.1255 - val_accuracy: 0.9648 - val_loss: 0.1247\n",
            "Epoch 6/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9706 - loss: 0.1062 - val_accuracy: 0.9675 - val_loss: 0.1123\n",
            "Epoch 7/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9728 - loss: 0.0950 - val_accuracy: 0.9684 - val_loss: 0.1080\n",
            "Epoch 8/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9781 - loss: 0.0819 - val_accuracy: 0.9699 - val_loss: 0.1007\n",
            "Epoch 9/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9789 - loss: 0.0732 - val_accuracy: 0.9702 - val_loss: 0.0991\n",
            "Epoch 10/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9837 - loss: 0.0624 - val_accuracy: 0.9706 - val_loss: 0.0971\n",
            "Epoch 11/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9845 - loss: 0.0567 - val_accuracy: 0.9722 - val_loss: 0.0967\n",
            "Epoch 12/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9865 - loss: 0.0506 - val_accuracy: 0.9708 - val_loss: 0.0938\n",
            "Epoch 13/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9869 - loss: 0.0485 - val_accuracy: 0.9719 - val_loss: 0.0925\n",
            "Epoch 14/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9893 - loss: 0.0425 - val_accuracy: 0.9735 - val_loss: 0.0915\n",
            "Epoch 15/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9911 - loss: 0.0374 - val_accuracy: 0.9739 - val_loss: 0.0955\n",
            "Epoch 16/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9907 - loss: 0.0349 - val_accuracy: 0.9746 - val_loss: 0.0929\n",
            "Epoch 17/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0310 - val_accuracy: 0.9735 - val_loss: 0.0913\n",
            "Epoch 18/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9932 - loss: 0.0283 - val_accuracy: 0.9741 - val_loss: 0.0897\n",
            "Epoch 19/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9935 - loss: 0.0256 - val_accuracy: 0.9741 - val_loss: 0.0892\n",
            "Epoch 20/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9947 - loss: 0.0236 - val_accuracy: 0.9733 - val_loss: 0.0953\n",
            "Epoch 21/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.0215 - val_accuracy: 0.9751 - val_loss: 0.0891\n",
            "Epoch 22/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9964 - loss: 0.0174 - val_accuracy: 0.9740 - val_loss: 0.0939\n",
            "Epoch 23/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9963 - loss: 0.0173 - val_accuracy: 0.9748 - val_loss: 0.0935\n",
            "Epoch 24/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9968 - loss: 0.0149 - val_accuracy: 0.9740 - val_loss: 0.0956\n",
            "Epoch 25/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9974 - loss: 0.0140 - val_accuracy: 0.9749 - val_loss: 0.0975\n",
            "Epoch 26/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0118 - val_accuracy: 0.9738 - val_loss: 0.1018\n",
            "Epoch 27/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9977 - loss: 0.0117 - val_accuracy: 0.9735 - val_loss: 0.1038\n",
            "Epoch 28/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0104 - val_accuracy: 0.9750 - val_loss: 0.1019\n",
            "Epoch 29/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0094 - val_accuracy: 0.9750 - val_loss: 0.1049\n",
            "Epoch 30/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0091 - val_accuracy: 0.9756 - val_loss: 0.1028\n",
            "Epoch 31/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0070 - val_accuracy: 0.9755 - val_loss: 0.1022\n",
            "Best epoch: 21\n",
            "Epoch 1/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8100 - loss: 0.7103\n",
            "Epoch 2/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9387 - loss: 0.2176\n",
            "Epoch 3/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9534 - loss: 0.1623\n",
            "Epoch 4/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.1309\n",
            "Epoch 5/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9688 - loss: 0.1089\n",
            "Epoch 6/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9727 - loss: 0.0929\n",
            "Epoch 7/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9762 - loss: 0.0807\n",
            "Epoch 8/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9785 - loss: 0.0749\n",
            "Epoch 9/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9820 - loss: 0.0635\n",
            "Epoch 10/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.0566\n",
            "Epoch 11/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: 0.0484\n",
            "Epoch 12/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9870 - loss: 0.0473\n",
            "Epoch 13/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9885 - loss: 0.0415\n",
            "Epoch 14/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0375\n",
            "Epoch 15/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9902 - loss: 0.0343\n",
            "Epoch 16/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.0313\n",
            "Epoch 17/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9922 - loss: 0.0277\n",
            "Epoch 18/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9933 - loss: 0.0254\n",
            "Epoch 19/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0225\n",
            "Epoch 20/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9949 - loss: 0.0226\n",
            "Epoch 21/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9949 - loss: 0.0194\n",
            "Epoch 22/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0168\n",
            "Epoch 23/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9967 - loss: 0.0157\n",
            "Epoch 24/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9959 - loss: 0.0167\n",
            "Epoch 25/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9969 - loss: 0.0140\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9721 - loss: 0.1068\n",
            "Epoch 1/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7967 - loss: 0.7585 - val_accuracy: 0.9334 - val_loss: 0.2399\n",
            "Epoch 2/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9332 - loss: 0.2372 - val_accuracy: 0.9522 - val_loss: 0.1810\n",
            "Epoch 3/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9488 - loss: 0.1816 - val_accuracy: 0.9593 - val_loss: 0.1495\n",
            "Epoch 4/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9577 - loss: 0.1465 - val_accuracy: 0.9597 - val_loss: 0.1369\n",
            "Epoch 5/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9640 - loss: 0.1261 - val_accuracy: 0.9641 - val_loss: 0.1266\n",
            "Epoch 6/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9701 - loss: 0.1052 - val_accuracy: 0.9663 - val_loss: 0.1162\n",
            "Epoch 7/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9731 - loss: 0.0933 - val_accuracy: 0.9677 - val_loss: 0.1113\n",
            "Epoch 8/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9773 - loss: 0.0806 - val_accuracy: 0.9703 - val_loss: 0.1002\n",
            "Epoch 9/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9797 - loss: 0.0728 - val_accuracy: 0.9690 - val_loss: 0.0980\n",
            "Epoch 10/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9827 - loss: 0.0627 - val_accuracy: 0.9701 - val_loss: 0.1021\n",
            "Epoch 11/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9840 - loss: 0.0567 - val_accuracy: 0.9712 - val_loss: 0.0951\n",
            "Epoch 12/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9849 - loss: 0.0514 - val_accuracy: 0.9721 - val_loss: 0.0948\n",
            "Epoch 13/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9870 - loss: 0.0467 - val_accuracy: 0.9734 - val_loss: 0.0939\n",
            "Epoch 14/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9889 - loss: 0.0440 - val_accuracy: 0.9727 - val_loss: 0.0937\n",
            "Epoch 15/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9891 - loss: 0.0390 - val_accuracy: 0.9718 - val_loss: 0.0972\n",
            "Epoch 16/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9908 - loss: 0.0351 - val_accuracy: 0.9724 - val_loss: 0.0941\n",
            "Epoch 17/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0317 - val_accuracy: 0.9714 - val_loss: 0.0975\n",
            "Epoch 18/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0282 - val_accuracy: 0.9733 - val_loss: 0.0905\n",
            "Epoch 19/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9931 - loss: 0.0264 - val_accuracy: 0.9723 - val_loss: 0.0945\n",
            "Epoch 20/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9942 - loss: 0.0234 - val_accuracy: 0.9732 - val_loss: 0.0922\n",
            "Epoch 21/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9955 - loss: 0.0203 - val_accuracy: 0.9724 - val_loss: 0.0935\n",
            "Epoch 22/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9957 - loss: 0.0191 - val_accuracy: 0.9726 - val_loss: 0.0993\n",
            "Epoch 23/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0179 - val_accuracy: 0.9724 - val_loss: 0.0972\n",
            "Epoch 24/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9969 - loss: 0.0161 - val_accuracy: 0.9734 - val_loss: 0.0971\n",
            "Epoch 25/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0140 - val_accuracy: 0.9726 - val_loss: 0.1026\n",
            "Epoch 26/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 0.0119 - val_accuracy: 0.9725 - val_loss: 0.1021\n",
            "Epoch 27/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0116 - val_accuracy: 0.9733 - val_loss: 0.1031\n",
            "Epoch 28/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9974 - loss: 0.0118 - val_accuracy: 0.9733 - val_loss: 0.1020\n",
            "Best epoch: 18\n",
            "Epoch 1/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7935 - loss: 0.7511\n",
            "Epoch 2/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9402 - loss: 0.2116\n",
            "Epoch 3/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9538 - loss: 0.1603\n",
            "Epoch 4/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.1281\n",
            "Epoch 5/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9707 - loss: 0.1032\n",
            "Epoch 6/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9746 - loss: 0.0918\n",
            "Epoch 7/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9780 - loss: 0.0780\n",
            "Epoch 8/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.0700\n",
            "Epoch 9/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9816 - loss: 0.0642\n",
            "Epoch 10/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9839 - loss: 0.0567\n",
            "Epoch 11/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9860 - loss: 0.0487\n",
            "Epoch 12/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9873 - loss: 0.0438\n",
            "Epoch 13/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9889 - loss: 0.0396\n",
            "Epoch 14/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9907 - loss: 0.0353\n",
            "Epoch 15/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9910 - loss: 0.0320\n",
            "Epoch 16/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9927 - loss: 0.0277\n",
            "Epoch 17/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9932 - loss: 0.0275\n",
            "Epoch 18/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9928 - loss: 0.0254\n",
            "Epoch 19/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9949 - loss: 0.0215\n",
            "Epoch 20/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9952 - loss: 0.0196\n",
            "Epoch 21/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0170\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9699 - loss: 0.1022\n"
          ]
        }
      ],
      "source": [
        "def get_best_trained_model(hp):\n",
        "    best_epoch = get_best_epoch(hp)\n",
        "    model = build_model(hp)\n",
        "    model.fit(\n",
        "        x_train_full, y_train_full,\n",
        "        batch_size=128, epochs=int(best_epoch * 1.2))\n",
        "    return model\n",
        "\n",
        "best_models = []\n",
        "for hp in best_hps:\n",
        "    model = get_best_trained_model(hp)\n",
        "    model.evaluate(x_test, y_test)\n",
        "    best_models.append(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "d9LqKEpfZqR4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9cf5d29-67c4-424f-d3bc-2835594db741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "best_models = tuner.get_best_models(top_n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}