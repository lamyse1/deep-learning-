{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lamyse1/deep-learning-/blob/main/Week6/DL_Week6_Ex2_chapter10_dl_for_timeseries_i.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qrbA0Qu5nja"
      },
      "source": [
        "\n",
        "# AAI612: Deep Learning & its Applications\n",
        "\n",
        "*Notebook 6.3: Understanding recurrent neural networks*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiuQYJOz5njb"
      },
      "source": [
        "**Read and parse the data of the Jena weather dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "csBXVX755njc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97e1b6c9-5059-4065-9033-a143481e310c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\"Date Time\"', '\"p (mbar)\"', '\"T (degC)\"', '\"Tpot (K)\"', '\"Tdew (degC)\"', '\"rh (%)\"', '\"VPmax (mbar)\"', '\"VPact (mbar)\"', '\"VPdef (mbar)\"', '\"sh (g/kg)\"', '\"H2OC (mmol/mol)\"', '\"rho (g/m**3)\"', '\"wv (m/s)\"', '\"max. wv (m/s)\"', '\"wd (deg)\"']\n",
            "420451\n",
            "num_train_samples: 210225\n",
            "num_val_samples: 105112\n",
            "num_test_samples: 105114\n"
          ]
        }
      ],
      "source": [
        "import ssl\n",
        "from urllib.request import urlopen\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/harmanani/AAI612/main/Week6/data/jena_climate_2009_2016.csv\"\n",
        "\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "f = urlopen(url)\n",
        "data = f.read()\n",
        "\n",
        "lines = data.decode().split(\"\\n\")\n",
        "header = lines[0].split(\",\")\n",
        "lines = lines[1:]\n",
        "print(header)\n",
        "print(len(lines))\n",
        "\n",
        "import numpy as np\n",
        "temperature = np.zeros((len(lines),))\n",
        "raw_data = np.zeros((len(lines), len(header) - 1))\n",
        "for i, line in enumerate(lines):\n",
        "    values = [float(x) for x in line.split(\",\")[1:]]\n",
        "    temperature[i] = values[1]\n",
        "    raw_data[i, :] = values[:]\n",
        "\n",
        "num_train_samples = int(0.5 * len(raw_data))\n",
        "num_val_samples = int(0.25 * len(raw_data))\n",
        "num_test_samples = len(raw_data) - num_train_samples - num_val_samples\n",
        "print(\"num_train_samples:\", num_train_samples)\n",
        "print(\"num_val_samples:\", num_val_samples)\n",
        "print(\"num_test_samples:\", num_test_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3LfESLl5njc"
      },
      "source": [
        "**Compute the number of samples we'll use for each data split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nb-8WlqX5njc"
      },
      "outputs": [],
      "source": [
        "import keras.utils\n",
        "\n",
        "sampling_rate = 6\n",
        "sequence_length = 120\n",
        "delay = sampling_rate * (sequence_length + 24 - 1)\n",
        "batch_size = 256\n",
        "\n",
        "train_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    raw_data[:-delay],\n",
        "    targets=temperature[delay:],\n",
        "    sampling_rate=sampling_rate,\n",
        "    sequence_length=sequence_length,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    start_index=0,\n",
        "    end_index=num_train_samples)\n",
        "\n",
        "val_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    raw_data[:-delay],\n",
        "    targets=temperature[delay:],\n",
        "    sampling_rate=sampling_rate,\n",
        "    sequence_length=sequence_length,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    start_index=num_train_samples,\n",
        "    end_index=num_train_samples + num_val_samples)\n",
        "\n",
        "test_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    raw_data[:-delay],\n",
        "    targets=temperature[delay:],\n",
        "    sampling_rate=sampling_rate,\n",
        "    sequence_length=sequence_length,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    start_index=num_train_samples + num_val_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFYPNFH25njd"
      },
      "source": [
        "**NumPy implementation of a simple RNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vP55rlJq5njd"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "timesteps = 100\n",
        "input_features = 32\n",
        "output_features = 64\n",
        "inputs = np.random.random((timesteps, input_features))\n",
        "state_t = np.zeros((output_features,))\n",
        "W = np.random.random((output_features, input_features))\n",
        "U = np.random.random((output_features, output_features))\n",
        "b = np.random.random((output_features,))\n",
        "successive_outputs = []\n",
        "for input_t in inputs:\n",
        "    output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)\n",
        "    successive_outputs.append(output_t)\n",
        "    state_t = output_t\n",
        "final_output_sequence = np.stack(successive_outputs, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGqexLZz5njd"
      },
      "source": [
        "### A recurrent layer in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBQKRlIr5njd"
      },
      "source": [
        "**An RNN layer that can process sequences of any length**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8JbeYPyq5nje"
      },
      "outputs": [],
      "source": [
        "num_features = 14\n",
        "inputs = keras.Input(shape=(None, num_features))\n",
        "outputs = layers.SimpleRNN(16)(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMj0-K5n5nje"
      },
      "source": [
        "**An RNN layer that returns only its last output step**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bOZ-kEIa5nje",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a874bade-3995-435b-ee02-fe580d3ae46b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 16)\n"
          ]
        }
      ],
      "source": [
        "num_features = 14\n",
        "steps = 120\n",
        "inputs = keras.Input(shape=(steps, num_features))\n",
        "outputs = layers.SimpleRNN(16, return_sequences=False)(inputs)\n",
        "print(outputs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mknXvtU75nje"
      },
      "source": [
        "**An RNN layer that returns its full output sequence**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7sJRSycv5nje",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "306ce331-afd6-4b1f-a3a3-787ed21752da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 120, 16)\n"
          ]
        }
      ],
      "source": [
        "num_features = 14\n",
        "steps = 120\n",
        "inputs = keras.Input(shape=(steps, num_features))\n",
        "outputs = layers.SimpleRNN(16, return_sequences=True)(inputs)\n",
        "print(outputs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O9K1j095nje"
      },
      "source": [
        "**Stacking RNN layers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ACrZKTER5nje"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(steps, num_features))\n",
        "x = layers.SimpleRNN(16, return_sequences=True)(inputs)\n",
        "x = layers.SimpleRNN(16, return_sequences=True)(x)\n",
        "outputs = layers.SimpleRNN(16)(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qznls8BF5nje"
      },
      "source": [
        "## Advanced use of recurrent neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQTJXjFN5nje"
      },
      "source": [
        "### Using recurrent dropout to fight overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVckjVUz5nje"
      },
      "source": [
        "**Training and evaluating a dropout-regularized LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFQO-MB65nje",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afde043b-c116-40a3-a167-a67afc2403e8"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 183ms/step - loss: 105.3189 - mae: 8.2555 - val_loss: 41.7394 - val_mae: 5.0458\n",
            "Epoch 2/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 182ms/step - loss: 51.5413 - mae: 5.5818 - val_loss: 29.2365 - val_mae: 4.2302\n",
            "Epoch 3/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 199ms/step - loss: 42.5867 - mae: 5.0537 - val_loss: 21.7118 - val_mae: 3.5278\n",
            "Epoch 4/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 180ms/step - loss: 39.7507 - mae: 4.8855 - val_loss: 20.8236 - val_mae: 3.5274\n",
            "Epoch 5/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 183ms/step - loss: 38.8931 - mae: 4.8393 - val_loss: 22.4874 - val_mae: 3.7345\n",
            "Epoch 6/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 182ms/step - loss: 38.3420 - mae: 4.7932 - val_loss: 25.6884 - val_mae: 4.0652\n",
            "Epoch 7/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 199ms/step - loss: 38.2484 - mae: 4.7844 - val_loss: 19.4372 - val_mae: 3.4083\n",
            "Epoch 8/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 180ms/step - loss: 37.8002 - mae: 4.7572 - val_loss: 19.3838 - val_mae: 3.4220\n",
            "Epoch 9/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 182ms/step - loss: 37.7632 - mae: 4.7477 - val_loss: 18.9069 - val_mae: 3.3635\n",
            "Epoch 10/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 182ms/step - loss: 36.8049 - mae: 4.6770 - val_loss: 18.2378 - val_mae: 3.2844\n",
            "Epoch 11/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 183ms/step - loss: 35.9791 - mae: 4.6292 - val_loss: 21.4012 - val_mae: 3.6146\n",
            "Epoch 12/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 182ms/step - loss: 35.8491 - mae: 4.6184 - val_loss: 17.3382 - val_mae: 3.1947\n",
            "Epoch 13/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 182ms/step - loss: 35.7935 - mae: 4.6242 - val_loss: 17.6101 - val_mae: 3.2466\n",
            "Epoch 14/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 184ms/step - loss: 35.5661 - mae: 4.6095 - val_loss: 19.2291 - val_mae: 3.3857\n",
            "Epoch 15/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 181ms/step - loss: 35.5595 - mae: 4.6055 - val_loss: 16.6884 - val_mae: 3.1179\n",
            "Epoch 16/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 182ms/step - loss: 35.2567 - mae: 4.5854 - val_loss: 17.6304 - val_mae: 3.2572\n",
            "Epoch 17/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 182ms/step - loss: 35.8126 - mae: 4.6298 - val_loss: 16.9303 - val_mae: 3.1380\n",
            "Epoch 18/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 180ms/step - loss: 35.3785 - mae: 4.5907 - val_loss: 16.4205 - val_mae: 3.1050\n",
            "Epoch 19/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 183ms/step - loss: 35.4237 - mae: 4.5940 - val_loss: 18.4051 - val_mae: 3.3361\n",
            "Epoch 20/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 182ms/step - loss: 35.4546 - mae: 4.6007 - val_loss: 16.3066 - val_mae: 3.0759\n",
            "Epoch 21/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 182ms/step - loss: 35.3181 - mae: 4.5893 - val_loss: 22.5457 - val_mae: 3.8003\n",
            "Epoch 22/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 181ms/step - loss: 35.1073 - mae: 4.5764 - val_loss: 22.1725 - val_mae: 3.7703\n",
            "Epoch 23/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 186ms/step - loss: 35.5585 - mae: 4.6004 - val_loss: 16.7032 - val_mae: 3.1148\n",
            "Epoch 24/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 182ms/step - loss: 35.3615 - mae: 4.5889 - val_loss: 16.7565 - val_mae: 3.1169\n",
            "Epoch 25/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 183ms/step - loss: 35.4671 - mae: 4.5974 - val_loss: 18.0889 - val_mae: 3.3100\n",
            "Epoch 26/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 197ms/step - loss: 35.3868 - mae: 4.5933 - val_loss: 16.2883 - val_mae: 3.0798\n",
            "Epoch 27/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 183ms/step - loss: 35.5741 - mae: 4.6016 - val_loss: 16.3720 - val_mae: 3.0783\n",
            "Epoch 28/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 199ms/step - loss: 35.2003 - mae: 4.5773 - val_loss: 21.0565 - val_mae: 3.6613\n",
            "Epoch 29/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 182ms/step - loss: 35.2812 - mae: 4.5808 - val_loss: 20.1255 - val_mae: 3.5376\n",
            "Epoch 30/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 182ms/step - loss: 35.5260 - mae: 4.5980 - val_loss: 19.5776 - val_mae: 3.4964\n",
            "Epoch 31/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 184ms/step - loss: 35.7611 - mae: 4.6176 - val_loss: 16.2876 - val_mae: 3.0697\n",
            "Epoch 32/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 181ms/step - loss: 35.6593 - mae: 4.6100 - val_loss: 17.6446 - val_mae: 3.2394\n",
            "Epoch 33/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 187ms/step - loss: 35.2714 - mae: 4.5900 - val_loss: 17.3494 - val_mae: 3.2128\n",
            "Epoch 34/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 182ms/step - loss: 35.8943 - mae: 4.6241 - val_loss: 16.3318 - val_mae: 3.0680\n",
            "Epoch 35/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 181ms/step - loss: 35.6665 - mae: 4.6102 - val_loss: 17.5539 - val_mae: 3.2226\n",
            "Epoch 36/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 182ms/step - loss: 35.1303 - mae: 4.5728 - val_loss: 16.7946 - val_mae: 3.1549\n",
            "Epoch 37/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 187ms/step - loss: 35.3012 - mae: 4.5833 - val_loss: 22.8341 - val_mae: 3.8411\n",
            "Epoch 38/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 182ms/step - loss: 35.2317 - mae: 4.5763 - val_loss: 22.1029 - val_mae: 3.7076\n",
            "Epoch 39/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 183ms/step - loss: 35.1216 - mae: 4.5747 - val_loss: 18.8934 - val_mae: 3.3895\n",
            "Epoch 40/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 183ms/step - loss: 35.0873 - mae: 4.5626 - val_loss: 16.4674 - val_mae: 3.0945\n",
            "Epoch 41/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 182ms/step - loss: 34.9607 - mae: 4.5650 - val_loss: 16.6372 - val_mae: 3.1213\n",
            "Epoch 42/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 180ms/step - loss: 35.1970 - mae: 4.5780 - val_loss: 18.3781 - val_mae: 3.3304\n",
            "Epoch 43/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 182ms/step - loss: 35.6857 - mae: 4.6073 - val_loss: 19.8767 - val_mae: 3.5185\n",
            "Epoch 44/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 181ms/step - loss: 35.4365 - mae: 4.5948 - val_loss: 17.7097 - val_mae: 3.2352\n",
            "Epoch 45/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 182ms/step - loss: 35.2243 - mae: 4.5771 - val_loss: 16.2848 - val_mae: 3.0712\n",
            "Epoch 46/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 180ms/step - loss: 35.1589 - mae: 4.5697 - val_loss: 15.8015 - val_mae: 3.0277\n",
            "Epoch 47/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 200ms/step - loss: 35.1396 - mae: 4.5760 - val_loss: 17.7509 - val_mae: 3.2498\n",
            "Epoch 48/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 179ms/step - loss: 35.5740 - mae: 4.6069 - val_loss: 15.6708 - val_mae: 3.0059\n",
            "Epoch 49/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 182ms/step - loss: 36.4418 - mae: 4.6790 - val_loss: 16.5071 - val_mae: 3.1012\n",
            "Epoch 50/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 179ms/step - loss: 35.2937 - mae: 4.5931 - val_loss: 17.7023 - val_mae: 3.2601\n"
          ]
        }
      ],
      "source": [
        "sequence_length = 120\n",
        "\n",
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.LSTM(32, recurrent_dropout=0.25)(inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"jena_lstm_dropout.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=50,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyKlUSgr5njf"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(sequence_length, num_features))\n",
        "x = layers.LSTM(32, recurrent_dropout=0.2, unroll=True)(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xR8eRBN5njf"
      },
      "source": [
        "### Stacking recurrent layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYyyMzhs5njf"
      },
      "source": [
        "**Training and evaluating a dropout-regularized, stacked GRU model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBB7gO2T5njf",
        "outputId": "9cc67195-78e5-49c8-c061-efa3bc48c540",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 299ms/step - loss: 56.4791 - mae: 5.7452 - val_loss: 21.0452 - val_mae: 3.6194\n",
            "Epoch 2/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 294ms/step - loss: 23.7852 - mae: 3.8563 - val_loss: 17.7771 - val_mae: 3.3013\n",
            "Epoch 3/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 300ms/step - loss: 23.3388 - mae: 3.8169 - val_loss: 19.3402 - val_mae: 3.4555\n",
            "Epoch 4/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 297ms/step - loss: 22.9988 - mae: 3.7983 - val_loss: 17.6210 - val_mae: 3.2871\n",
            "Epoch 5/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 293ms/step - loss: 22.6119 - mae: 3.7525 - val_loss: 17.0765 - val_mae: 3.2105\n",
            "Epoch 6/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 295ms/step - loss: 22.4251 - mae: 3.7366 - val_loss: 18.0137 - val_mae: 3.3435\n",
            "Epoch 7/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 296ms/step - loss: 22.0421 - mae: 3.7103 - val_loss: 18.6777 - val_mae: 3.4039\n",
            "Epoch 8/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 296ms/step - loss: 21.6022 - mae: 3.6762 - val_loss: 17.2323 - val_mae: 3.2215\n",
            "Epoch 9/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 299ms/step - loss: 21.3185 - mae: 3.6470 - val_loss: 16.7187 - val_mae: 3.1732\n",
            "Epoch 10/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 299ms/step - loss: 21.1452 - mae: 3.6270 - val_loss: 18.0213 - val_mae: 3.3125\n",
            "Epoch 11/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 302ms/step - loss: 20.9605 - mae: 3.6161 - val_loss: 18.2390 - val_mae: 3.3108\n",
            "Epoch 12/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 306ms/step - loss: 20.8561 - mae: 3.6028 - val_loss: 18.6780 - val_mae: 3.3665\n",
            "Epoch 13/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 301ms/step - loss: 20.7161 - mae: 3.5999 - val_loss: 18.8232 - val_mae: 3.3767\n",
            "Epoch 14/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 298ms/step - loss: 20.6233 - mae: 3.5853 - val_loss: 23.3186 - val_mae: 3.8155\n",
            "Epoch 15/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 300ms/step - loss: 20.5119 - mae: 3.5719 - val_loss: 17.5340 - val_mae: 3.2483\n",
            "Epoch 16/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 296ms/step - loss: 20.4233 - mae: 3.5682 - val_loss: 17.0049 - val_mae: 3.2128\n",
            "Epoch 17/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 296ms/step - loss: 20.2480 - mae: 3.5525 - val_loss: 17.9027 - val_mae: 3.3121\n",
            "Epoch 18/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 302ms/step - loss: 20.1035 - mae: 3.5394 - val_loss: 16.4895 - val_mae: 3.1480\n",
            "Epoch 19/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 300ms/step - loss: 20.1601 - mae: 3.5436 - val_loss: 19.8576 - val_mae: 3.4731\n",
            "Epoch 20/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 297ms/step - loss: 20.1285 - mae: 3.5416 - val_loss: 16.9840 - val_mae: 3.2106\n",
            "Epoch 21/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 298ms/step - loss: 19.9387 - mae: 3.5268 - val_loss: 17.5123 - val_mae: 3.2558\n",
            "Epoch 22/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 301ms/step - loss: 20.0255 - mae: 3.5314 - val_loss: 17.6291 - val_mae: 3.2648\n",
            "Epoch 23/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 295ms/step - loss: 19.8142 - mae: 3.5208 - val_loss: 17.0513 - val_mae: 3.2188\n",
            "Epoch 24/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 301ms/step - loss: 19.7779 - mae: 3.5141 - val_loss: 17.4627 - val_mae: 3.2606\n",
            "Epoch 25/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 298ms/step - loss: 19.6989 - mae: 3.5006 - val_loss: 19.7583 - val_mae: 3.4990\n",
            "Epoch 26/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 296ms/step - loss: 19.8135 - mae: 3.5155 - val_loss: 17.3013 - val_mae: 3.2323\n",
            "Epoch 27/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 301ms/step - loss: 19.6584 - mae: 3.4985 - val_loss: 18.0156 - val_mae: 3.2880\n",
            "Epoch 28/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 296ms/step - loss: 19.6008 - mae: 3.4938 - val_loss: 17.3479 - val_mae: 3.2429\n",
            "Epoch 29/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 298ms/step - loss: 19.5919 - mae: 3.4930 - val_loss: 17.5631 - val_mae: 3.2805\n",
            "Epoch 30/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 297ms/step - loss: 19.5810 - mae: 3.4903 - val_loss: 17.7914 - val_mae: 3.2851\n",
            "Epoch 31/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 293ms/step - loss: 19.5184 - mae: 3.4860 - val_loss: 16.9941 - val_mae: 3.2244\n",
            "Epoch 32/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 298ms/step - loss: 19.5157 - mae: 3.4872 - val_loss: 16.4571 - val_mae: 3.1535\n",
            "Epoch 33/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 300ms/step - loss: 19.3783 - mae: 3.4777 - val_loss: 17.3490 - val_mae: 3.2524\n",
            "Epoch 34/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 295ms/step - loss: 19.3252 - mae: 3.4720 - val_loss: 17.0273 - val_mae: 3.2042\n",
            "Epoch 35/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 302ms/step - loss: 19.3231 - mae: 3.4739 - val_loss: 17.1169 - val_mae: 3.2274\n",
            "Epoch 36/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 299ms/step - loss: 19.3979 - mae: 3.4792 - val_loss: 17.9059 - val_mae: 3.3331\n",
            "Epoch 37/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 293ms/step - loss: 19.4217 - mae: 3.4812 - val_loss: 17.8509 - val_mae: 3.3077\n",
            "Epoch 38/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 296ms/step - loss: 19.3238 - mae: 3.4672 - val_loss: 18.1779 - val_mae: 3.3280\n",
            "Epoch 39/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 296ms/step - loss: 19.2464 - mae: 3.4620 - val_loss: 16.5924 - val_mae: 3.1698\n",
            "Epoch 40/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 295ms/step - loss: 19.2336 - mae: 3.4620 - val_loss: 16.7071 - val_mae: 3.1885\n",
            "Epoch 41/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 293ms/step - loss: 19.1555 - mae: 3.4541 - val_loss: 17.0156 - val_mae: 3.2134\n",
            "Epoch 42/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 293ms/step - loss: 19.2380 - mae: 3.4624 - val_loss: 16.9511 - val_mae: 3.2087\n",
            "Epoch 43/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 293ms/step - loss: 19.0963 - mae: 3.4495 - val_loss: 17.3541 - val_mae: 3.2513\n",
            "Epoch 44/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 296ms/step - loss: 19.1337 - mae: 3.4508 - val_loss: 17.0799 - val_mae: 3.2244\n",
            "Epoch 45/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 293ms/step - loss: 19.0385 - mae: 3.4446 - val_loss: 16.6602 - val_mae: 3.1794\n",
            "Epoch 46/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 293ms/step - loss: 19.1182 - mae: 3.4490 - val_loss: 16.8101 - val_mae: 3.1937\n",
            "Epoch 47/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 294ms/step - loss: 19.0365 - mae: 3.4431 - val_loss: 16.1293 - val_mae: 3.1282\n",
            "Epoch 48/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 298ms/step - loss: 18.9896 - mae: 3.4404 - val_loss: 16.7229 - val_mae: 3.1848\n",
            "Epoch 49/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 301ms/step - loss: 18.9849 - mae: 3.4365 - val_loss: 16.1107 - val_mae: 3.1314\n",
            "Epoch 50/50\n",
            "\u001b[1m109/819\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:55\u001b[0m 247ms/step - loss: 18.9356 - mae: 3.4268"
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.GRU(32, recurrent_dropout=0.5, return_sequences=True)(inputs)\n",
        "x = layers.GRU(32, recurrent_dropout=0.5)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"jena_stacked_gru_dropout.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=50,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=callbacks)\n",
        "\n",
        "model = keras.models.load_model(\"jena_stacked_gru_dropout.keras\")\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6cSTKj-5njf"
      },
      "source": [
        "### Using bidirectional RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOciccfb5njf"
      },
      "source": [
        "**Training and evaluating a bidirectional LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RDs_yJGg5njf",
        "outputId": "b7bdd2df-6e51-4ced-bfc7-dbc7b843c550",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 169ms/step - loss: 109.4151 - mae: 8.4838 - val_loss: 57.7342 - val_mae: 6.1306\n",
            "Epoch 2/10\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 166ms/step - loss: 59.4063 - mae: 6.0730 - val_loss: 42.4590 - val_mae: 5.1656\n",
            "Epoch 3/10\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 166ms/step - loss: 49.1452 - mae: 5.4131 - val_loss: 35.6415 - val_mae: 4.6782\n",
            "Epoch 4/10\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 169ms/step - loss: 41.4281 - mae: 4.9114 - val_loss: 29.8749 - val_mae: 4.2427\n",
            "Epoch 5/10\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 168ms/step - loss: 35.4405 - mae: 4.5192 - val_loss: 26.6965 - val_mae: 4.0179\n",
            "Epoch 6/10\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 170ms/step - loss: 30.9284 - mae: 4.2270 - val_loss: 24.1940 - val_mae: 3.7863\n",
            "Epoch 7/10\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 168ms/step - loss: 27.6501 - mae: 4.0117 - val_loss: 23.7829 - val_mae: 3.8072\n",
            "Epoch 8/10\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 169ms/step - loss: 25.2994 - mae: 3.8613 - val_loss: 21.6911 - val_mae: 3.6349\n",
            "Epoch 9/10\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 170ms/step - loss: 23.7506 - mae: 3.7667 - val_loss: 20.3427 - val_mae: 3.4996\n",
            "Epoch 10/10\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 169ms/step - loss: 22.7002 - mae: 3.6932 - val_loss: 20.6221 - val_mae: 3.5534\n"
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.Bidirectional(layers.LSTM(16))(inputs)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=10,\n",
        "                    validation_data=val_dataset)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}