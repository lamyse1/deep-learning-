{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lamyse1/deep-learning-/blob/main/Week6/DL_Week6_Ex2_chapter10_dl_for_timeseries_i.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qrbA0Qu5nja"
      },
      "source": [
        "\n",
        "# AAI612: Deep Learning & its Applications\n",
        "\n",
        "*Notebook 6.3: Understanding recurrent neural networks*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiuQYJOz5njb"
      },
      "source": [
        "**Read and parse the data of the Jena weather dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "csBXVX755njc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b04f021-6ae1-4079-b484-df0787e77e42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\"Date Time\"', '\"p (mbar)\"', '\"T (degC)\"', '\"Tpot (K)\"', '\"Tdew (degC)\"', '\"rh (%)\"', '\"VPmax (mbar)\"', '\"VPact (mbar)\"', '\"VPdef (mbar)\"', '\"sh (g/kg)\"', '\"H2OC (mmol/mol)\"', '\"rho (g/m**3)\"', '\"wv (m/s)\"', '\"max. wv (m/s)\"', '\"wd (deg)\"']\n",
            "420451\n",
            "num_train_samples: 210225\n",
            "num_val_samples: 105112\n",
            "num_test_samples: 105114\n"
          ]
        }
      ],
      "source": [
        "import ssl\n",
        "from urllib.request import urlopen\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/harmanani/AAI612/main/Week6/data/jena_climate_2009_2016.csv\"\n",
        "\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "f = urlopen(url)\n",
        "data = f.read()\n",
        "\n",
        "lines = data.decode().split(\"\\n\")\n",
        "header = lines[0].split(\",\")\n",
        "lines = lines[1:]\n",
        "print(header)\n",
        "print(len(lines))\n",
        "\n",
        "import numpy as np\n",
        "temperature = np.zeros((len(lines),))\n",
        "raw_data = np.zeros((len(lines), len(header) - 1))\n",
        "for i, line in enumerate(lines):\n",
        "    values = [float(x) for x in line.split(\",\")[1:]]\n",
        "    temperature[i] = values[1]\n",
        "    raw_data[i, :] = values[:]\n",
        "\n",
        "num_train_samples = int(0.5 * len(raw_data))\n",
        "num_val_samples = int(0.25 * len(raw_data))\n",
        "num_test_samples = len(raw_data) - num_train_samples - num_val_samples\n",
        "print(\"num_train_samples:\", num_train_samples)\n",
        "print(\"num_val_samples:\", num_val_samples)\n",
        "print(\"num_test_samples:\", num_test_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3LfESLl5njc"
      },
      "source": [
        "**Compute the number of samples we'll use for each data split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nb-8WlqX5njc"
      },
      "outputs": [],
      "source": [
        "import keras.utils\n",
        "\n",
        "sampling_rate = 6\n",
        "sequence_length = 120\n",
        "delay = sampling_rate * (sequence_length + 24 - 1)\n",
        "batch_size = 256\n",
        "\n",
        "train_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    raw_data[:-delay],\n",
        "    targets=temperature[delay:],\n",
        "    sampling_rate=sampling_rate,\n",
        "    sequence_length=sequence_length,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    start_index=0,\n",
        "    end_index=num_train_samples)\n",
        "\n",
        "val_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    raw_data[:-delay],\n",
        "    targets=temperature[delay:],\n",
        "    sampling_rate=sampling_rate,\n",
        "    sequence_length=sequence_length,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    start_index=num_train_samples,\n",
        "    end_index=num_train_samples + num_val_samples)\n",
        "\n",
        "test_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    raw_data[:-delay],\n",
        "    targets=temperature[delay:],\n",
        "    sampling_rate=sampling_rate,\n",
        "    sequence_length=sequence_length,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    start_index=num_train_samples + num_val_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFYPNFH25njd"
      },
      "source": [
        "**NumPy implementation of a simple RNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vP55rlJq5njd"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "timesteps = 100\n",
        "input_features = 32\n",
        "output_features = 64\n",
        "inputs = np.random.random((timesteps, input_features))\n",
        "state_t = np.zeros((output_features,))\n",
        "W = np.random.random((output_features, input_features))\n",
        "U = np.random.random((output_features, output_features))\n",
        "b = np.random.random((output_features,))\n",
        "successive_outputs = []\n",
        "for input_t in inputs:\n",
        "    output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)\n",
        "    successive_outputs.append(output_t)\n",
        "    state_t = output_t\n",
        "final_output_sequence = np.stack(successive_outputs, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGqexLZz5njd"
      },
      "source": [
        "### A recurrent layer in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBQKRlIr5njd"
      },
      "source": [
        "**An RNN layer that can process sequences of any length**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8JbeYPyq5nje"
      },
      "outputs": [],
      "source": [
        "num_features = 14\n",
        "inputs = keras.Input(shape=(None, num_features))\n",
        "outputs = layers.SimpleRNN(16)(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMj0-K5n5nje"
      },
      "source": [
        "**An RNN layer that returns only its last output step**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bOZ-kEIa5nje",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d781f27-ca55-4aef-9fc2-0f8622000a5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 16)\n"
          ]
        }
      ],
      "source": [
        "num_features = 14\n",
        "steps = 120\n",
        "inputs = keras.Input(shape=(steps, num_features))\n",
        "outputs = layers.SimpleRNN(16, return_sequences=False)(inputs)\n",
        "print(outputs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mknXvtU75nje"
      },
      "source": [
        "**An RNN layer that returns its full output sequence**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7sJRSycv5nje",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ab4546e-91fb-4081-8b29-0d4146f3f9a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 120, 16)\n"
          ]
        }
      ],
      "source": [
        "num_features = 14\n",
        "steps = 120\n",
        "inputs = keras.Input(shape=(steps, num_features))\n",
        "outputs = layers.SimpleRNN(16, return_sequences=True)(inputs)\n",
        "print(outputs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O9K1j095nje"
      },
      "source": [
        "**Stacking RNN layers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ACrZKTER5nje"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(steps, num_features))\n",
        "x = layers.SimpleRNN(16, return_sequences=True)(inputs)\n",
        "x = layers.SimpleRNN(16, return_sequences=True)(x)\n",
        "outputs = layers.SimpleRNN(16)(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qznls8BF5nje"
      },
      "source": [
        "## Advanced use of recurrent neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQTJXjFN5nje"
      },
      "source": [
        "### Using recurrent dropout to fight overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVckjVUz5nje"
      },
      "source": [
        "**Training and evaluating a dropout-regularized LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sFQO-MB65nje",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afde043b-c116-40a3-a167-a67afc2403e8"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 183ms/step - loss: 105.3189 - mae: 8.2555 - val_loss: 41.7394 - val_mae: 5.0458\n",
            "Epoch 2/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 182ms/step - loss: 51.5413 - mae: 5.5818 - val_loss: 29.2365 - val_mae: 4.2302\n",
            "Epoch 3/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 199ms/step - loss: 42.5867 - mae: 5.0537 - val_loss: 21.7118 - val_mae: 3.5278\n",
            "Epoch 4/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 180ms/step - loss: 39.7507 - mae: 4.8855 - val_loss: 20.8236 - val_mae: 3.5274\n",
            "Epoch 5/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 183ms/step - loss: 38.8931 - mae: 4.8393 - val_loss: 22.4874 - val_mae: 3.7345\n",
            "Epoch 6/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 182ms/step - loss: 38.3420 - mae: 4.7932 - val_loss: 25.6884 - val_mae: 4.0652\n",
            "Epoch 7/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 199ms/step - loss: 38.2484 - mae: 4.7844 - val_loss: 19.4372 - val_mae: 3.4083\n",
            "Epoch 8/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 180ms/step - loss: 37.8002 - mae: 4.7572 - val_loss: 19.3838 - val_mae: 3.4220\n",
            "Epoch 9/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 182ms/step - loss: 37.7632 - mae: 4.7477 - val_loss: 18.9069 - val_mae: 3.3635\n",
            "Epoch 10/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 182ms/step - loss: 36.8049 - mae: 4.6770 - val_loss: 18.2378 - val_mae: 3.2844\n",
            "Epoch 11/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 183ms/step - loss: 35.9791 - mae: 4.6292 - val_loss: 21.4012 - val_mae: 3.6146\n",
            "Epoch 12/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 182ms/step - loss: 35.8491 - mae: 4.6184 - val_loss: 17.3382 - val_mae: 3.1947\n",
            "Epoch 13/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 182ms/step - loss: 35.7935 - mae: 4.6242 - val_loss: 17.6101 - val_mae: 3.2466\n",
            "Epoch 14/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 184ms/step - loss: 35.5661 - mae: 4.6095 - val_loss: 19.2291 - val_mae: 3.3857\n",
            "Epoch 15/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 181ms/step - loss: 35.5595 - mae: 4.6055 - val_loss: 16.6884 - val_mae: 3.1179\n",
            "Epoch 16/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 182ms/step - loss: 35.2567 - mae: 4.5854 - val_loss: 17.6304 - val_mae: 3.2572\n",
            "Epoch 17/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 182ms/step - loss: 35.8126 - mae: 4.6298 - val_loss: 16.9303 - val_mae: 3.1380\n",
            "Epoch 18/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 180ms/step - loss: 35.3785 - mae: 4.5907 - val_loss: 16.4205 - val_mae: 3.1050\n",
            "Epoch 19/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 183ms/step - loss: 35.4237 - mae: 4.5940 - val_loss: 18.4051 - val_mae: 3.3361\n",
            "Epoch 20/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 182ms/step - loss: 35.4546 - mae: 4.6007 - val_loss: 16.3066 - val_mae: 3.0759\n",
            "Epoch 21/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 182ms/step - loss: 35.3181 - mae: 4.5893 - val_loss: 22.5457 - val_mae: 3.8003\n",
            "Epoch 22/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 181ms/step - loss: 35.1073 - mae: 4.5764 - val_loss: 22.1725 - val_mae: 3.7703\n",
            "Epoch 23/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 186ms/step - loss: 35.5585 - mae: 4.6004 - val_loss: 16.7032 - val_mae: 3.1148\n",
            "Epoch 24/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 182ms/step - loss: 35.3615 - mae: 4.5889 - val_loss: 16.7565 - val_mae: 3.1169\n",
            "Epoch 25/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 183ms/step - loss: 35.4671 - mae: 4.5974 - val_loss: 18.0889 - val_mae: 3.3100\n",
            "Epoch 26/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 197ms/step - loss: 35.3868 - mae: 4.5933 - val_loss: 16.2883 - val_mae: 3.0798\n",
            "Epoch 27/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 183ms/step - loss: 35.5741 - mae: 4.6016 - val_loss: 16.3720 - val_mae: 3.0783\n",
            "Epoch 28/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 199ms/step - loss: 35.2003 - mae: 4.5773 - val_loss: 21.0565 - val_mae: 3.6613\n",
            "Epoch 29/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 182ms/step - loss: 35.2812 - mae: 4.5808 - val_loss: 20.1255 - val_mae: 3.5376\n",
            "Epoch 30/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 182ms/step - loss: 35.5260 - mae: 4.5980 - val_loss: 19.5776 - val_mae: 3.4964\n",
            "Epoch 31/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 184ms/step - loss: 35.7611 - mae: 4.6176 - val_loss: 16.2876 - val_mae: 3.0697\n",
            "Epoch 32/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 181ms/step - loss: 35.6593 - mae: 4.6100 - val_loss: 17.6446 - val_mae: 3.2394\n",
            "Epoch 33/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 187ms/step - loss: 35.2714 - mae: 4.5900 - val_loss: 17.3494 - val_mae: 3.2128\n",
            "Epoch 34/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 182ms/step - loss: 35.8943 - mae: 4.6241 - val_loss: 16.3318 - val_mae: 3.0680\n",
            "Epoch 35/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 181ms/step - loss: 35.6665 - mae: 4.6102 - val_loss: 17.5539 - val_mae: 3.2226\n",
            "Epoch 36/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 182ms/step - loss: 35.1303 - mae: 4.5728 - val_loss: 16.7946 - val_mae: 3.1549\n",
            "Epoch 37/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 187ms/step - loss: 35.3012 - mae: 4.5833 - val_loss: 22.8341 - val_mae: 3.8411\n",
            "Epoch 38/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 182ms/step - loss: 35.2317 - mae: 4.5763 - val_loss: 22.1029 - val_mae: 3.7076\n",
            "Epoch 39/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 183ms/step - loss: 35.1216 - mae: 4.5747 - val_loss: 18.8934 - val_mae: 3.3895\n",
            "Epoch 40/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 183ms/step - loss: 35.0873 - mae: 4.5626 - val_loss: 16.4674 - val_mae: 3.0945\n",
            "Epoch 41/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 182ms/step - loss: 34.9607 - mae: 4.5650 - val_loss: 16.6372 - val_mae: 3.1213\n",
            "Epoch 42/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 180ms/step - loss: 35.1970 - mae: 4.5780 - val_loss: 18.3781 - val_mae: 3.3304\n",
            "Epoch 43/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 182ms/step - loss: 35.6857 - mae: 4.6073 - val_loss: 19.8767 - val_mae: 3.5185\n",
            "Epoch 44/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 181ms/step - loss: 35.4365 - mae: 4.5948 - val_loss: 17.7097 - val_mae: 3.2352\n",
            "Epoch 45/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 182ms/step - loss: 35.2243 - mae: 4.5771 - val_loss: 16.2848 - val_mae: 3.0712\n",
            "Epoch 46/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 180ms/step - loss: 35.1589 - mae: 4.5697 - val_loss: 15.8015 - val_mae: 3.0277\n",
            "Epoch 47/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 200ms/step - loss: 35.1396 - mae: 4.5760 - val_loss: 17.7509 - val_mae: 3.2498\n",
            "Epoch 48/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 179ms/step - loss: 35.5740 - mae: 4.6069 - val_loss: 15.6708 - val_mae: 3.0059\n",
            "Epoch 49/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 182ms/step - loss: 36.4418 - mae: 4.6790 - val_loss: 16.5071 - val_mae: 3.1012\n",
            "Epoch 50/50\n",
            "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 179ms/step - loss: 35.2937 - mae: 4.5931 - val_loss: 17.7023 - val_mae: 3.2601\n"
          ]
        }
      ],
      "source": [
        "sequence_length = 120\n",
        "\n",
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.LSTM(32, recurrent_dropout=0.25)(inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"jena_lstm_dropout.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=50,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyKlUSgr5njf"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(sequence_length, num_features))\n",
        "x = layers.LSTM(32, recurrent_dropout=0.2, unroll=True)(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xR8eRBN5njf"
      },
      "source": [
        "### Stacking recurrent layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYyyMzhs5njf"
      },
      "source": [
        "**Training and evaluating a dropout-regularized, stacked GRU model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBB7gO2T5njf"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.GRU(32, recurrent_dropout=0.5, return_sequences=True)(inputs)\n",
        "x = layers.GRU(32, recurrent_dropout=0.5)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"jena_stacked_gru_dropout.x\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=50,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=callbacks)\n",
        "\n",
        "model = keras.models.load_model(\"jena_stacked_gru_dropout.x\")\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6cSTKj-5njf"
      },
      "source": [
        "### Using bidirectional RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOciccfb5njf"
      },
      "source": [
        "**Training and evaluating a bidirectional LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDs_yJGg5njf"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.Bidirectional(layers.LSTM(16))(inputs)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=10,\n",
        "                    validation_data=val_dataset)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}